{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"import numpy as np\nimport time\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D\nfrom skimage import io\nfrom glob import glob\nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import zipfile\n#with zipfile.ZipFile('../input/test-data.zip', 'r') as zip_ref:\n    #zip_ref.extractall('../input/test-d')\n\ntrain_path=\"../input/new-train/op_4_900/\"\nval_path='../input/new-test/newtest/drive-download-20200803T091955Z-001/'\nmcc_path=\"../input/mcc-test/\"\n\ntrain_images=[]\ntrain_masks=[]\nval_images=[]\nval_masks=[]\nmcc_images=[]\nmcc_masks=[]\ndef load_images(path):\n    temp_img,temp_mask=[],[]\n    images=glob(os.path.join(path,'*.png'))\n    for i in tqdm(images):\n        i=cv2.imread(i)\n        i=cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n        i=cv2.normalize(i,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n        \n        img=i[:,:256]\n        msk=i[:,256:]  \n        temp_img.append(img)\n        temp_mask.append(msk)\n    return temp_img,temp_mask\n\ndef load_mcc_images(path):\n    temp_img,temp_mask=[],[]\n    images=glob(os.path.join(path,'*.png'))\n    for i in tqdm(images):\n        i=cv2.imread(i)\n        i=cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n        i=cv2.normalize(i,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n        \n        img=i[:,:512]\n       \n        temp_img.append(img)\n        \n    return temp_img\n\ntrain_images,train_masks=load_images(train_path)\nval_images,val_masks=load_images(val_path)\nmcc_images=load_mcc_images(mcc_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Reading data. Before running this code, the dataset should be added to the notebook using the Kaggle functionality (or by any other means). In this block we read the first image\n#and make sure everything works\npath = '../input/new-train/op_4_900/'\nflist = os.listdir(path)\n\nimg0 = cv2.cvtColor(cv2.imread(path+flist[0]),cv2.COLOR_BGR2RGB)\n\nplt.imshow(img0)\nprint(np.shape(img0))\nprint(len(flist))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#reading the actual images and forming them into the training dataset\nszy,szx,_ = np.shape(img0)\nN_ex = 1500\nN_bias = 0\nx_train = np.zeros((N_ex,szy,int(szx/2),3))\ny_train = np.zeros((N_ex,szy,int(szx/2),3))\nk = 0;\n\nfor f in flist[N_bias:N_bias+N_ex]:\n    x_train[k] = cv2.cvtColor(cv2.imread(path+f),cv2.COLOR_BGR2RGB)[:,:256]/256\n    y_train[k] = cv2.cvtColor(cv2.imread(path+f),cv2.COLOR_BGR2RGB)[:,256:]/256\n    k = k+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"plt.figure(figsize = (15,15))\nplt.subplot(1,2,1)\nplt.imshow(x_train[1])\nplt.subplot(1,2,2)\nplt.imshow(y_train[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#same for the validation data\npath = '../input/new-test/newtest/drive-download-20200803T091955Z-001/'\nflist = os.listdir(path)\nimg0 = cv2.imread(path+flist[0])\nN_val = 100\n\nszy,szx,_ = np.shape(img0)\nx_val = np.zeros((N_val,szy,int(szx/2),3))\ny_val = np.zeros((N_val,szy,int(szx/2),3))\nk = 0;\n\nfor f in flist[0:N_val]:\n    x_train[k] = cv2.cvtColor(cv2.imread(path+f),cv2.COLOR_BGR2RGB)[:,:256]/256\n    y_train[k] = cv2.cvtColor(cv2.imread(path+f),cv2.COLOR_BGR2RGB)[:,256:]/256\n    k = k+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#u-net architecture\nimport tensorflow as tf\nimport keras\n\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Input, Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, UpSampling2D, Concatenate\nfrom keras.layers.convolutional import Conv2D\nfrom keras.models import Sequential, Model, model_from_json, load_model\nfrom keras.regularizers import l2\n\n\n# define conv_factory: batch normalization + ReLU + Conv2D + Dropout (optional)\ndef conv_factory(x, concat_axis, nb_filter,\n                 dropout_rate=None, weight_decay=1E-4):\n    x = BatchNormalization(axis=concat_axis,\n                           gamma_regularizer=l2(weight_decay),\n                           beta_regularizer=l2(weight_decay))(x)\n    x = Activation('relu')(x)\n    x = Conv2D(nb_filter, (5, 5), dilation_rate=(2, 2),\n               kernel_initializer=\"he_uniform\",\n               padding=\"same\",\n               kernel_regularizer=l2(weight_decay))(x)\n    if dropout_rate:\n        x = Dropout(dropout_rate)(x)\n  \n    return x\n\n\n# define dense block: a nb_layers stack of conv_factory layers merged together\ndef denseblock(x, concat_axis, nb_layers, growth_rate, dropout_rate=None, weight_decay=1E-4):\n    list_feat = [x]\n    for i in range(nb_layers):\n        x = conv_factory(x, concat_axis, growth_rate,dropout_rate, weight_decay)\n        list_feat.append(x)\n    x = Concatenate(axis=concat_axis)(list_feat)\n\n    return x\n\n\n# define model U-net modified with dense block\ndef u_net():\n    dr = 0.5\n    nr = 2\n    mod_inputs = Input((256,256,3))\n    print(\"inputs shape:\", mod_inputs.shape) #input layer\n\n    conv1 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mod_inputs)\n    print(\"conv1 shape:\", conv1.shape)\n    db1 = denseblock(x=conv1, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db1 shape:\", db1.shape)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(db1)\n    print(\"pool1 shape:\", pool1.shape)\n\n    conv2 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n    print(\"conv2 shape:\", conv2.shape)\n    db2 = denseblock(x=conv2, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db2 shape:\", db2.shape)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(db2)\n    print(\"pool2 shape:\", pool2.shape)\n\n    conv3 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n    print(\"conv3 shape:\", conv3.shape)\n    db3 = denseblock(x=conv3, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db3 shape:\", db3.shape)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(db3)\n    print(\"pool3 shape:\", pool3.shape)\n\n    conv4 = Conv2D(512/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n    print(\"conv4 shape:\", conv4.shape)\n    db4 = denseblock(x=conv4, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db4 shape:\", db4.shape)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(db4)\n    print(\"pool4 shape:\", pool4.shape)\n#################this is the bottleneck######################################\n    conv5 = Conv2D(1024/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n    print(\"conv5 shape:\", conv5.shape)\n    db5 = denseblock(x=conv5, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n    print(\"db5 shape:\", db5.shape)\n    up5 = Conv2D(512/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db5))\n    print(\"up5 shape:\", up5.shape)\n    merge5 = Concatenate(axis=3)([ BatchNormalization()(db4), BatchNormalization()( up5)]) #skip connection db4 to up5\n    print(\"merge5 shape:\", merge5.shape)\n\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n    print(\"conv6 shape:\", conv6.shape)\n    db6 = denseblock(x=conv6, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n    print(\"db5 shape:\", db6.shape)\n    up6 = Conv2D(256/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db6))\n    print(\"up6 shape:\", up6.shape)\n    merge6 = Concatenate(axis=3)([BatchNormalization()(db3), BatchNormalization()(up6)]) #skip connection db3 to up6\n    print(\"merge6 shape:\", merge6.shape)\n\n    conv7 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n    print(\"conv7 shape:\", conv7.shape)\n    db7 = denseblock(x=conv7, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db7 shape:\", db7.shape)\n    up7 = Conv2D(128/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(db7))\n    print(\"up7 shape:\", up7.shape)\n    merge7 = Concatenate(axis=3)([BatchNormalization()(db2), BatchNormalization()(up7)]) #skip connection db2 to up7\n    print(\"merge7 shape:\", merge7.shape)\n\n    conv8 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n    print(\"conv8 shape:\", conv8.shape)\n    db8 = denseblock(x=conv8, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db8 shape:\", db8.shape)\n    up8 = Conv2D(64/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(db8))\n    print(\"up8 shape:\", up8.shape)\n    merge8 = Concatenate(axis=3)([BatchNormalization()(db1), BatchNormalization()(up8)]) #skip connection db1 to up8\n    print(\"merge8 shape:\", merge8.shape)\n\n    conv9 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n    print(\"conv9 shape:\", conv9.shape)\n    db9 = denseblock(x=conv9, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db9 shape:\", db9.shape)\n    conv10 = Conv2D(32/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(db9) # final node layer\n    print(\"conv10 shape:\", conv10.shape)\n    conv11 = Conv2D(3, 1, activation='sigmoid')(conv10)  #output layer matched in size with the input\n    print(\"conv11 shape:\", conv11.shape)\n\n    model = Model(inputs=mod_inputs, outputs=conv11) \n    model.compile(optimizer='adam', loss = 'MSE')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model = u_net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"hist = model.fit(np.array(train_images,dtype='float16'),np.array(train_masks,dtype='float16'),epochs= 2, batch_size= 10,\n          validation_data=(np.array(val_images,dtype='float16'),np.array(val_masks,dtype='float16')))\ntf.keras.models.save_model(model,'/kaggle/working/best_modelnew_ep_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"''' hist = model.fit(x_train, y_train, epochs=10, shuffle = True, batch_size= 10, validation_data=(x_val, y_val))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.load_weights('./best_model2_e_40.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_imgs(img,mask,pred):\n    mask = np.reshape(mask,(256,256,3))\n    pred = np.reshape(pred,(256,256,3))\n    fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,10))\n    ax1.imshow(img)\n    ax1.axis('off')\n    ax2.imshow(mask)\n    ax2.axis('off')\n    ax3.imshow(pred)\n    ax3.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_masks = model.predict(np.array(mcc_images,dtype='float16'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('-------------Input---------------Actual mask--------------Predicted mask-------')\nfor i in range(6):\n    x = np.random.randint(0,6,size=1)[0]\n    #print(x)\n    plot_imgs(mcc_images[x],mcc_images[x],pred_masks[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" pp = model.predict(np.array(val_images,dtype='float16'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def u_net_wihtout_skips():\n    dr = 0.5\n    nr = 2\n    mod_inputs = Input((256,256,3))\n    print(\"inputs shape:\", mod_inputs.shape)\n\n    conv1 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mod_inputs)\n    print(\"conv1 shape:\", conv1.shape)\n    db1 = denseblock(x=conv1, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db1 shape:\", db1.shape)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(db1)\n    print(\"pool1 shape:\", pool1.shape)\n\n    conv2 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n    print(\"conv2 shape:\", conv2.shape)\n    db2 = denseblock(x=conv2, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db2 shape:\", db2.shape)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(db2)\n    print(\"pool2 shape:\", pool2.shape)\n\n    conv3 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n    print(\"conv3 shape:\", conv3.shape)\n    db3 = denseblock(x=conv3, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db3 shape:\", db3.shape)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(db3)\n    print(\"pool3 shape:\", pool3.shape)\n\n    conv4 = Conv2D(512/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n    print(\"conv4 shape:\", conv4.shape)\n    db4 = denseblock(x=conv4, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n    print(\"db4 shape:\", db4.shape)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(db4)\n    print(\"pool4 shape:\", pool4.shape)\n###############################################################################################################\n    conv5 = Conv2D(1024/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n    print(\"conv5 shape:\", conv5.shape)\n    db5 = denseblock(x=conv5, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n    print(\"db5 shape:\", db5.shape)\n    up5 = Conv2D(512/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db5))\n    print(\"up5 shape:\", up5.shape)\n    #merge5 = Concatenate(axis=3)([ BatchNormalization()(db4), BatchNormalization()( up5)])\n    #print(\"merge5 shape:\", merge5.shape)\n\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up5) #was merge5\n    print(\"conv6 shape:\", conv6.shape)\n    db6 = denseblock(x=conv6, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n    print(\"db5 shape:\", db6.shape)\n    up6 = Conv2D(256/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db6))\n    print(\"up6 shape:\", up6.shape)\n    #merge6 = Concatenate(axis=3)([BatchNormalization()(db3), BatchNormalization()(up6)])\n    #print(\"merge6 shape:\", merge6.shape)\n\n    conv7 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up6)#was merge6\n    print(\"conv7 shape:\", conv7.shape)\n    db7 = denseblock(x=conv7, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db7 shape:\", db7.shape)\n    up7 = Conv2D(128/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(db7))\n    print(\"up7 shape:\", up7.shape)\n    #merge7 = Concatenate(axis=3)([BatchNormalization()(db2), BatchNormalization()(up7)])\n    #print(\"merge7 shape:\", merge7.shape)\n\n    conv8 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up7) #was merge7\n    print(\"conv8 shape:\", conv8.shape)\n    db8 = denseblock(x=conv8, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db8 shape:\", db8.shape)\n    up8 = Conv2D(64/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(db8))\n    print(\"up8 shape:\", up8.shape)\n    #merge8 = Concatenate(axis=3)([BatchNormalization()(db1), BatchNormalization()(up8)])\n    #print(\"merge8 shape:\", merge8.shape)\n\n    conv9 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up8)#was merge8\n    print(\"conv9 shape:\", conv9.shape)\n    db9 = denseblock(x=conv9, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n    print(\"db9 shape:\", db9.shape)\n    conv10 = Conv2D(32/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(db9)\n    print(\"conv10 shape:\", conv10.shape)\n    conv11 = Conv2D(3, 1, activation='sigmoid')(conv10)\n    print(\"conv11 shape:\", conv11.shape)\n\n    model = Model(inputs=mod_inputs, outputs=conv11)\n    model.compile(optimizer='adam', loss = 'MSE')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nc = u_net_wihtout_skips()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nc.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his_nc = model_nc.fit(np.array(train_images,dtype='float16'),np.array(train_masks,dtype='float16'),epochs= 20, batch_size= 10,\n          validation_data=(np.array(val_images,dtype='float16'),np.array(val_masks,dtype='float16')))\n#tf.keras.models.save_model(model,'/kaggle/working/best_model2_e35.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pp_nc = model_nc.predict(val_images[0:20,:,:,:])\npp_nc = model_nc.predict(np.array(val_images,dtype='float16'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ni = 10\nfor k in range(ni):\n\n    plt.figure(figsize=(10,30))\n    plt.subplot(ni,4,1+k*4)\n    plt.imshow(x_val[k])\n    plt.subplot(ni,4,2+k*4)\n    plt.imshow(y_val[k])\n    plt.subplot(ni,4,3+k*4)\n    plt.imshow(pp_nc[k]) #without skips\n    plt.subplot(ni,4,4+k*4)\n    plt.imshow(pp[k]) #with skips","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training mse\nplt.plot(hist.history['loss'])\nplt.plot(his_nc.history['loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#show the result\nni = 10\nfor k in range(ni):\n\n    plt.figure(figsize=(10,30))\n    plt.subplot(ni,3,1+k*3)\n    plt.imshow(x_val[k])\n    plt.subplot(ni,3,2+k*3)\n    plt.imshow(y_val[k])\n    plt.subplot(ni,3,3+k*3)\n    plt.imshow(pp[k])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation mse\nplt.plot(hist.history['val_loss'])\nplt.plot(his_nc.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}